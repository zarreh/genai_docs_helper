# GenAI Docs Helper ğŸ¤–ğŸ“š

An intelligent document retrieval and question-answering system powered by LangChain and LangGraph. This project demonstrates advanced RAG (Retrieval-Augmented Generation) techniques with production-ready features including caching, performance monitoring, and intelligent retry mechanisms.

## ğŸŒŸ Features

- **Intelligent Document Retrieval**: Multi-strategy retrieval system with fast, standard, and comprehensive paths
- **Advanced RAG Pipeline**: Implements document grading, answer validation, and hallucination detection
- **Performance Optimization**: 
  - Redis/Memory dual-layer caching
  - Parallel document retrieval
  - Early stopping mechanisms
  - Batch processing for efficiency
- **Production-Ready Monitoring**: Comprehensive logging and performance metrics
- **Flexible Architecture**: Modular design with LangGraph for complex workflows
- **Multiple LLM Support**: Compatible with OpenAI and Ollama models

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    A[User Question] --> B[Retrieve Documents]
    B --> C[Grade Documents]
    C --> D{Relevant Docs Found?}
    D -->|Yes| E[Generate Answer]
    D -->|No| F[Paraphrase Question]
    F --> B
    E --> G[Check Hallucination]
    G --> H{Answer Quality OK?}
    H -->|Yes| I[Return Answer]
    H -->|No| F
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Poetry for dependency management
- Redis (optional, for caching)
- Ollama or OpenAI API key

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/genai_docs_helper.git
cd genai_docs_helper

# Install dependencies
poetry install

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Data Preparation

```bash
# Load and embed documents into vector store
make ingest
```

### Running the Application

```bash
# Run the main graph workflow
make run

# Or use LangGraph Studio for interactive development
make graph
```

## ğŸ“ Project Structure

```
genai_docs_helper/
â”œâ”€â”€ nodes/                      # Core processing nodes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ retrieve.py            # Multi-strategy document retrieval
â”‚   â”œâ”€â”€ grade_documents.py     # Batch relevance assessment
â”‚   â”œâ”€â”€ generate.py            # Answer generation with caching
â”‚   â”œâ”€â”€ paraphrase.py          # Query reformulation
â”‚   â””â”€â”€ README.md              # Detailed node documentation
â”œâ”€â”€ chains/                     # LangChain components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generation.py          # Answer generation chain
â”‚   â”œâ”€â”€ retrieval_grader.py    # Single document relevance grading
â”‚   â”œâ”€â”€ batch_grader.py        # Batch document grading
â”‚   â”œâ”€â”€ hallucination_grader.py # Hallucination detection
â”‚   â”œâ”€â”€ answer_grader.py       # Answer quality checker
â”‚   â”œâ”€â”€ paraphraser.py         # Question paraphrasing
â”‚   â”œâ”€â”€ query_expander.py      # Query expansion for better retrieval
â”‚   â”œâ”€â”€ confidence_scorer.py   # Document confidence scoring
â”‚   â”œâ”€â”€ document_reranker.py   # LLM-based document reranking
â”‚   â””â”€â”€ README.md              # Detailed chain documentation
â”œâ”€â”€ cache/                      # Caching system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_cache.py         # Dual-layer cache implementation
â”‚   â””â”€â”€ README.md              # Cache module documentation
â”œâ”€â”€ monitoring/                 # Performance monitoring
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ performance_monitor.py # Metrics collection and analysis
â”‚   â””â”€â”€ README.md              # Monitoring documentation
â”œâ”€â”€ utils/                      # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logging_config.py      # Centralized logging configuration
â”œâ”€â”€ legacy_graph/               # Legacy implementation (reference)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ chain.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/                      # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py            # Shared test fixtures
â”‚   â”œâ”€â”€ unit/                  # Unit tests
â”‚   â”‚   â”œâ”€â”€ nodes/             # Node-specific tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_retrieve.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_grade_documents.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_generate.py
â”‚   â”‚   â”‚   â””â”€â”€ test_paraphrase.py
â”‚   â”‚   â”œâ”€â”€ chains/            # Chain-specific tests
â”‚   â”‚   â”œâ”€â”€ cache/             # Cache tests
â”‚   â”‚   â”‚   â””â”€â”€ test_query_cache.py
â”‚   â”‚   â””â”€â”€ monitoring/        # Monitoring tests
â”‚   â”‚       â””â”€â”€ test_performance_monitor.py
â”‚   â””â”€â”€ integration/           # Integration tests
â”‚       â””â”€â”€ test_workflow.py
â”œâ”€â”€ docs/                       # Generated documentation (pdoc)
â”‚   â””â”€â”€ genai_docs_helper.html # Entry point for documentation
â”œâ”€â”€ logs/                       # Application logs
â”‚   â””â”€â”€ performance/           # Performance metrics logs
â”œâ”€â”€ state.py                    # Graph state management
â”œâ”€â”€ graph.py                    # Main workflow definition
â”œâ”€â”€ config.py                   # Configuration settings
â”œâ”€â”€ consts.py                   # Constants and node names
â”œâ”€â”€ loader_embed_to_vectore.py  # Document loading and embedding
â”œâ”€â”€ Makefile                    # Build and run commands
â”œâ”€â”€ pytest.ini                  # Test configuration
â”œâ”€â”€ pyproject.toml             # Project dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ§ª Testing

The project includes a comprehensive test suite with unit and integration tests.

### Running Tests

```bash
# Run all tests
make test

# Run unit tests only
make test-unit

# Run integration tests only
make test-integration

# Run with coverage report
make test-cov

# Run tests in parallel (faster)
make test-parallel

# Run specific test file
make test-specific TEST=tests/unit/nodes/test_retrieve.py

# Run tests in watch mode
make test-watch
```

### Test Coverage

The test suite aims for 80%+ code coverage and includes:
- âœ… All node functions with edge cases
- âœ… Chain components and prompt engineering
- âœ… Cache operations with Redis fallback
- âœ… Performance monitoring functionality
- âœ… Error handling and recovery scenarios
- âœ… End-to-end workflow integration

View the coverage report:
```bash
make test-cov
open htmlcov/index.html  # View detailed HTML coverage report
```

## ğŸ“– Documentation

### Generated Documentation

The project uses `pdoc` for automatic API documentation generation:

```bash
# Generate HTML documentation
make docs

# Serve documentation locally (http://localhost:8080)
make docs-serve

# Clean generated documentation
make docs-clean
```

### Module Documentation

Each major module includes its own README with detailed information:

- [**Nodes Module**](genai_docs_helper/nodes/README.md) - Core processing nodes documentation
- [**Chains Module**](genai_docs_helper/chains/README.md) - LangChain components documentation
- [**Cache Module**](genai_docs_helper/cache/README.md) - Caching system documentation
- [**Monitoring Module**](genai_docs_helper/monitoring/README.md) - Performance monitoring documentation

### API Documentation Structure

Once generated, the documentation includes:
- Complete API reference for all modules
- Type annotations and signatures
- Docstring documentation
- Source code browsing
- Cross-references between modules

Access the documentation at: `docs/genai_docs_helper.html`

## ğŸ”§ Configuration

Key configuration options in `config.py`:

```python
# LLM Selection
LLM_TYPE = "ollama"  # or "openai"

# Performance Settings
ENABLE_CACHE = False    # Toggle caching (set to False for debugging)
ENABLE_REDIS = False    # Use Redis (requires Redis server)
MAX_WORKERS = 5         # Parallel processing workers
BATCH_SIZE = 5          # Document grading batch size

# Retrieval Settings
RETRIEVAL_CONFIGS = {
    "fast": {"k": 20, "fetch_k": 40},
    "standard": {"k": 50, "fetch_k": 100},
    "comprehensive": {"k": 100, "fetch_k": 200}
}
```

## ğŸ“Š Performance Features

### 1. **Multi-Strategy Retrieval**
- **Fast Path**: Quick retrieval for time-sensitive queries (100-500ms)
- **Comprehensive Path**: Thorough search with query expansion
- **Fallback Mechanisms**: Graceful degradation on errors

### 2. **Intelligent Caching**
- Dual-layer cache (Redis + Memory)
- Automatic cache invalidation
- Cache hit rate monitoring
- Question-specific cache keys

### 3. **Performance Monitoring**
- Request-level metrics tracking
- Bottleneck identification
- Detailed performance logs
- JSON-based log analysis

## ğŸ› ï¸ Advanced Usage

### Custom Document Loaders

```python
from genai_docs_helper.loader_embed_to_vectore import load_markdown_files

# Load your custom documents
docs = load_markdown_files("./path/to/docs")
```

### Using Different Embeddings

```python
from genai_docs_helper.config import EMBEDDING

# Configure in config.py
EMBEDDING = OllamaEmbeddings(model="llama3.2")
```

### Monitoring Performance

```python
from genai_docs_helper.monitoring import PerformanceMonitor

monitor = PerformanceMonitor()
monitor.start_request("req-123")
# ... operations ...
summary = monitor.end_request("req-123")
```

### Analyzing Logs

```python
# Check logs directory
ls logs/

# View latest application log
tail -f logs/latest.log

# Analyze performance metrics
python -m genai_docs_helper.monitoring.analyze_logs
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com/) and [LangGraph](https://github.com/langchain-ai/langgraph)
- Vector storage powered by [Chroma](https://www.trychroma.com/)
- LLM support for [OpenAI](https://openai.com/) and [Ollama](https://ollama.ai/)

## ğŸ“§ Contact

Ali Zarreh - ali@zarreh.ai

Project Link: [https://github.com/zarreh/genai_docs_helper](https://github.com/zarreh/genai_docs_helper)