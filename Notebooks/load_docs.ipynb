{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6d45cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from typing import List\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c03745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0eea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alireza/projects/genai_docs_helper/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8e3cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialize document loader\n",
    "loader = DirectoryLoader('../data/docs/', glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "# Load documents\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfe5700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n## \", \"\\n### \", \"\\n#### \", \"\\n\", \" \", \"\"]  # Respects markdown headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ab94ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n",
      "Created 19 splits\n",
      "page_content='Time Series Forecasting with Facebook Prophet\n",
      "\n",
      "Overview\n",
      "\n",
      "This document details the process and results of a time series forecasting project using Facebook Prophet. The goal was to build a robust, interpretable model for predicting future values based on historical time series data. The workflow includes data preparation, exploratory analysis, model training, forecasting, and evaluation.\n",
      "\n",
      "Project Objectives\n",
      "\n",
      "Develop a time series forecasting model using Facebook Prophet.\n",
      "\n",
      "Visualize and interpret the forecast and its components.\n",
      "\n",
      "Evaluate model performance and identify areas for improvement.\n",
      "\n",
      "Data Preparation\n",
      "\n",
      "The dataset was loaded and preprocessed to fit Prophetâ€™s requirements. The key steps included:\n",
      "\n",
      "Loading Data: The time series data was imported, ensuring the date column was in the correct datetime format.\n",
      "\n",
      "Renaming Columns: Prophet requires columns to be named ds (datestamp) and y (value to forecast).' metadata={'source': '../data/docs/1_prophet.md'}\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks\n",
    "print(\"Splitting documents...\")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(splits)} splits\")\n",
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9cf5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3698111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store...\n",
      "Vector store created and persisted\n"
     ]
    }
   ],
   "source": [
    "# Create and persist vector store\n",
    "print(\"Creating vector store...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../data/chroma_db\"  # This will save the vector store locally\n",
    ")\n",
    "vectorstore.persist()\n",
    "print(\"Vector store created and persisted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "491ef942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10235/3505961457.py:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm=OpenAI(),\n"
     ]
    }
   ],
   "source": [
    "# Initialize retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(\n",
    "        search_kwargs={\"k\": 3}  # Retrieve top 3 most relevant chunks\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd7f88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query function with better formatting\n",
    "def ask_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Ask a question about the loaded documents.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to ask\n",
    "\n",
    "    Returns:\n",
    "        str: The answer from the model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = qa_chain.run(question)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bc1acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with sample question: What is this document about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10235/841156122.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:  This document is about the basics of time series analysis, including patterns, dependence, and stationarity.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the system with a sample question\n",
    "    sample_question = \"What is this document about?\"\n",
    "    print(\"\\nTesting with sample question:\", sample_question)\n",
    "    print(\"\\nAnswer:\", ask_question(sample_question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_genai_docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
