{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b6bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 5 markdown files and 13 notebooks\n",
      "Processing documents...\n",
      "Created 485 splits\n",
      "Creating vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60365/2804220640.py:86: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60365/2804220640.py:90: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n",
      "/tmp/ipykernel_60365/2804220640.py:96: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    # Demand Forecasting Q&A Session\n",
       "    Session started: 2025-04-28 21:44:05\n",
       "\n",
       "    Enter your questions below. Type 'exit' to end the session.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "*Processing your question...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60365/2804220640.py:135: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant specialized in demand forecasting and related topics.\n",
      "Use the following pieces of context to answer the question at the end.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Context: Machine Learning Project Documentation\n",
      "\n",
      "Project Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Welcome to the documentation for our machine learning project focused on time series analysis. This project aims to leverage modern techniques to analyze and forecast time series data, providing valuable insights and predictions.\n",
      "\n",
      "Objectives\n",
      "\n",
      "Develop a robust time series analysis toolkit.\n",
      "\n",
      "Implement various forecasting methods.\n",
      "\n",
      "Detect anomalies and change points in time series data.\n",
      "\n",
      "Provide comprehensive documentation and tutorials.\n",
      "\n",
      "Project Details\n",
      "\n",
      "Time Series Analysis Toolkit\n",
      "\n",
      "Overview\n",
      "\n",
      "Our time series analysis toolkit includes a variety of methods and models designed to handle different aspects of time series data. These include traditional statistical methods, machine learning models, and deep learning techniques.\n",
      "\n",
      "Methods and Models\n",
      "\n",
      "Exponential Smoothing: A classic method for forecasting time series data, including single, double, and triple exponential smoothing.\n",
      "\n",
      "Machine Learning Project Documentation\n",
      "\n",
      "Project Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Welcome to the documentation for our machine learning project focused on time series analysis. This project aims to leverage modern techniques to analyze and forecast time series data, providing valuable insights and predictions.\n",
      "\n",
      "Objectives\n",
      "\n",
      "Develop a robust time series analysis toolkit.\n",
      "\n",
      "Implement various forecasting methods.\n",
      "\n",
      "Detect anomalies and change points in time series data.\n",
      "\n",
      "Provide comprehensive documentation and tutorials.\n",
      "\n",
      "Project Details\n",
      "\n",
      "Time Series Analysis Toolkit\n",
      "\n",
      "Overview\n",
      "\n",
      "Our time series analysis toolkit includes a variety of methods and models designed to handle different aspects of time series data. These include traditional statistical methods, machine learning models, and deep learning techniques.\n",
      "\n",
      "Methods and Models\n",
      "\n",
      "Exponential Smoothing: A classic method for forecasting time series data, including single, double, and triple exponential smoothing.\n",
      "\n",
      "is split into three sections: we introduce the basic framework of linear processes, then present extensions and finally demonstrate how to solve a prediction problem from scratch. * [Basic linear processes](#section-one)* [Beyond ARMA](#section-two)* [Full pipeline](#section-three)* [A day at the races](#section-four)As usual, we begin by importing the required packages'\n",
      "\n",
      "Question: what are the steps of this project?\n",
      "\n",
      "Please provide your answer following these guidelines:\n",
      "1. Use ONLY information from the provided context\n",
      "2. ALWAYS cite your sources using [Source X] format where X is the source number\n",
      "3. If multiple sources support a statement, cite all relevant sources: [Source 1,2]\n",
      "4. If the context doesn't contain enough information, clearly state that\n",
      "5. Structure your response in a clear, logical manner\n",
      "6. Keep the answer focused and relevant to demand forecasting\n",
      "\n",
      "Remember: Every significant statement should have a source citation.\n",
      "\n",
      "Answer: Let me help you with that.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question\n",
       "what are the steps of this project?\n",
       "\n",
       "### Answer\n",
       "Based on the provided context, the steps of the machine learning project focused on time series analysis are as follows:\n",
       "\n",
       "1. Introduction: The project aims to leverage modern techniques to analyze and forecast time series data, providing valuable insights and predictions [Source 1].\n",
       "\n",
       "2. Objectives: The objectives of the project include developing a robust time series analysis toolkit, implementing various forecasting methods, detecting anomalies and change points in time series data, and providing comprehensive documentation and tutorials [Source 1].\n",
       "\n",
       "3. Time Series Analysis Toolkit: The toolkit includes a variety of methods and models designed to handle different aspects of time series data, such as traditional statistical methods, machine learning models, and deep learning techniques [Source 1].\n",
       "\n",
       "4. Methods and Models: The project utilizes exponential smoothing as a classic method for forecasting time series data, including single, double, and triple exponential smoothing [Source 1].\n",
       "\n",
       "Unfortunately, the specific steps of the project beyond these general objectives and components are not provided in the context.\n",
       "\n",
       "### References\n",
       "\n",
       "[Source 1] ../data/docs/0_project_overview.md\n",
       "> Machine Learning Project Documentation  Project Overview  Introduction  Welcome to the documentation for our machine learning project focused on time series analysis. This project aims to leverage mod...\n",
       "\n",
       "[Source 2] ../data/docs/0_project_overview.md\n",
       "> Machine Learning Project Documentation  Project Overview  Introduction  Welcome to the documentation for our machine learning project focused on time series analysis. This project aims to leverage mod...\n",
       "\n",
       "[Source 3] demand_forecast_notebooks/ts-2-linear-vision.ipynb\n",
       "> is split into three sections: we introduce the basic framework of linear processes, then present extensions and finally demonstrate how to solve a prediction problem from scratch. * [Basic linear proc...\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Session Ended\n",
       "Thank you for using the Q&A system!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required imports\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader, NotebookLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Custom prompt template\n",
    "custom_prompt_template = \"\"\"You are a helpful AI assistant specialized in demand forecasting and related topics.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide your answer following these guidelines:\n",
    "1. Use ONLY information from the provided context\n",
    "2. ALWAYS cite your sources using [Source X] format where X is the source number\n",
    "3. If multiple sources support a statement, cite all relevant sources: [Source 1,2]\n",
    "4. If the context doesn't contain enough information, clearly state that\n",
    "5. Structure your response in a clear, logical manner\n",
    "6. Keep the answer focused and relevant to demand forecasting\n",
    "\n",
    "Remember: Every significant statement should have a source citation.\n",
    "\n",
    "Answer: Let me help you with that.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "PROMPT = PromptTemplate(\n",
    "    template=custom_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "def load_markdown_files(directory: str = \"./data/docs/\") -> List:\n",
    "    \"\"\"Load markdown files from directory\"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        directory, glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "def load_jupyter_notebooks(directory: str = \"./demand_forecast_notebooks/\") -> List:\n",
    "    \"\"\"Load jupyter notebooks from directory\"\"\"\n",
    "    documents = []\n",
    "    for notebook_path in glob.glob(f\"{directory}/**/*.ipynb\", recursive=True):\n",
    "        if \".ipynb_checkpoints\" not in notebook_path:\n",
    "            try:\n",
    "                loader = NotebookLoader(\n",
    "                    notebook_path,\n",
    "                    include_outputs=True,\n",
    "                    max_output_length=50,\n",
    "                    remove_newline=True,\n",
    "                )\n",
    "                documents.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading notebook {notebook_path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "def process_documents(documents: List, chunk_size: int = 1000, chunk_overlap: int = 20):\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n## \", \"\\n### \", \"\\n#### \", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "def create_vector_store(documents: List, persist_directory: str = \"./data/chroma_db\"):\n",
    "    \"\"\"Create and persist vector store\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents, embedding=embeddings, persist_directory=persist_directory\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def setup_qa_chain(vectorstore):\n",
    "    \"\"\"Setup the QA chain with custom prompt\"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Create the QA chain with custom prompt - the k can be added to the function input variable\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        chain_type_kwargs={\"prompt\": PROMPT, \"verbose\": True},\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "def extract_relevant_context(doc) -> Dict:\n",
    "    \"\"\"Extract and format relevant context from a document.\"\"\"\n",
    "    return {\n",
    "        \"content\": doc.page_content,\n",
    "        \"source\": doc.metadata.get(\"source\", \"Unnamed Source\"),\n",
    "        \"page\": doc.metadata.get(\"page\", None),\n",
    "        \"chunk\": doc.metadata.get(\"chunk\", None),\n",
    "    }\n",
    "\n",
    "\n",
    "def format_citation(source_info: Dict) -> str:\n",
    "    \"\"\"Format source information into a citation.\"\"\"\n",
    "    citation = source_info[\"source\"]\n",
    "    if source_info[\"page\"]:\n",
    "        citation += f\", page {source_info['page']}\"\n",
    "    return citation\n",
    "\n",
    "\n",
    "def ask_question(qa_chain, question: str) -> str:\n",
    "    \"\"\"Ask a question and return a well-formatted answer with citations.\"\"\"\n",
    "    try:\n",
    "        # Get the answer and source documents\n",
    "        result = qa_chain({\"query\": question})\n",
    "\n",
    "        # Extract answer and sources\n",
    "        answer = result[\"result\"]\n",
    "        sources = result.get(\"source_documents\", [])\n",
    "\n",
    "        # Create source mapping\n",
    "        source_map = {}\n",
    "        for idx, doc in enumerate(sources, 1):\n",
    "            source_info = extract_relevant_context(doc)\n",
    "            source_map[idx] = source_info\n",
    "\n",
    "        # Format the response in Markdown\n",
    "        md = f\"### Question\\n{question}\\n\\n\"\n",
    "        md += f\"### Answer\\n{answer}\\n\\n\"\n",
    "\n",
    "        if source_map:\n",
    "            md += \"### References\\n\\n\"\n",
    "            for idx, source_info in source_map.items():\n",
    "                citation = format_citation(source_info)\n",
    "                md += f\"[Source {idx}] {citation}\\n\"\n",
    "                excerpt = source_info[\"content\"][:200].replace(\"\\n\", \" \").strip()\n",
    "                md += f\"> {excerpt}...\\n\\n\"\n",
    "\n",
    "        return md\n",
    "    except Exception as e:\n",
    "        return f\"**An error occurred:** {str(e)}\"\n",
    "\n",
    "\n",
    "def interactive_qa(qa_chain):\n",
    "    \"\"\"Interactive Q&A session with formatted Markdown output and citations.\"\"\"\n",
    "    try:\n",
    "        from IPython.display import display, Markdown, HTML\n",
    "\n",
    "        use_markdown = True\n",
    "    except ImportError:\n",
    "        use_markdown = False\n",
    "\n",
    "    session_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    header = f\"\"\"\n",
    "    # Demand Forecasting Q&A Session\n",
    "    Session started: {session_time}\n",
    "\n",
    "    Enter your questions below. Type 'exit' to end the session.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_markdown:\n",
    "        display(Markdown(header))\n",
    "    else:\n",
    "        print(header)\n",
    "\n",
    "    while True:\n",
    "        question = input(\"\\nYour question: \").strip()\n",
    "        if question.lower() == \"exit\":\n",
    "            footer = \"\\n### Session Ended\\nThank you for using the Q&A system!\"\n",
    "            if use_markdown:\n",
    "                display(Markdown(footer))\n",
    "            else:\n",
    "                print(footer)\n",
    "            break\n",
    "\n",
    "        if use_markdown:\n",
    "            display(Markdown(\"---\\n*Processing your question...*\"))\n",
    "        else:\n",
    "            print(\"\\nProcessing your question...\")\n",
    "\n",
    "        answer_md = ask_question(qa_chain, question)\n",
    "\n",
    "        if use_markdown:\n",
    "            display(Markdown(answer_md))\n",
    "            display(Markdown(\"---\"))\n",
    "        else:\n",
    "            print(answer_md)\n",
    "            print(\"---\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading documents...\")\n",
    "    markdown_docs = load_markdown_files(\"../data/docs/\")\n",
    "    notebook_docs = load_jupyter_notebooks(\"./demand_forecast_notebooks/\")\n",
    "\n",
    "    all_documents = markdown_docs + notebook_docs\n",
    "    print(\n",
    "        f\"Loaded {len(markdown_docs)} markdown files and {len(notebook_docs)} notebooks\"\n",
    "    )\n",
    "\n",
    "    print(\"Processing documents...\")\n",
    "    splits = process_documents(all_documents)\n",
    "    print(f\"Created {len(splits)} splits\")\n",
    "\n",
    "    print(\"Creating vector store...\")\n",
    "    vectorstore = create_vector_store(splits)\n",
    "    print(\"Vector store created and persisted\")\n",
    "\n",
    "    qa_chain = setup_qa_chain(vectorstore)\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qa_chain = main()\n",
    "    interactive_qa(qa_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_genai_docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
